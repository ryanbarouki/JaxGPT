{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca12f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('smiles.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec3c0c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = text[:1_000_000].encode('utf-8')\n",
    "tokens = list(map(int, tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee410e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging (99, 99) into a new token 256\n",
      "merging (79, 41) into a new token 257\n",
      "merging (99, 49) into a new token 258\n",
      "merging (40, 61) into a new token 259\n",
      "merging (259, 257) into a new token 260\n",
      "merging (99, 40) into a new token 261\n",
      "merging (67, 67) into a new token 262\n",
      "merging (99, 50) into a new token 263\n",
      "merging (41, 67) into a new token 264\n",
      "merging (258, 256) into a new token 265\n",
      "merging (99, 51) into a new token 266\n",
      "merging (261, 256) into a new token 267\n",
      "merging (67, 260) into a new token 268\n",
      "merging (72, 93) into a new token 269\n",
      "merging (10, 67) into a new token 270\n",
      "merging (263, 256) into a new token 271\n",
      "merging (91, 67) into a new token 272\n",
      "merging (272, 64) into a new token 273\n",
      "merging (40, 67) into a new token 274\n",
      "merging (10, 265) into a new token 275\n"
     ]
    }
   ],
   "source": [
    "def get_stats(ids):\n",
    "    counts = {}\n",
    "    for pair in zip(ids, ids[1:]):\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts\n",
    "\n",
    "def merge(ids, pair, idx):\n",
    "  newids = []\n",
    "  i = 0\n",
    "  while i < len(ids):\n",
    "    if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
    "      newids.append(idx)\n",
    "      i += 2\n",
    "    else:\n",
    "      newids.append(ids[i])\n",
    "      i += 1\n",
    "  return newids\n",
    "\n",
    "# ---\n",
    "vocab_size = 276 # the desired final vocabulary size\n",
    "num_merges = vocab_size - 256\n",
    "ids = list(tokens) # copy so we don't destroy the original list\n",
    "\n",
    "merges = {} # (int, int) -> int\n",
    "for i in range(num_merges):\n",
    "  stats = get_stats(ids)\n",
    "  pair = max(stats, key=stats.get)\n",
    "  idx = 256 + i\n",
    "  print(f\"merging {pair} into a new token {idx}\")\n",
    "  ids = merge(ids, pair, idx)\n",
    "  merges[pair] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a09b9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(ids):\n",
    "    rev_merge = {v:k for k,v in merges.items()}\n",
    "    def rec(subids, out=[]):\n",
    "        for id in subids:\n",
    "            if id < 256:\n",
    "                out.append(id)\n",
    "            else:\n",
    "                if id in rev_merge:\n",
    "                    rec(rev_merge[id], out)\n",
    "        return out\n",
    "    out = rec(ids)\n",
    "    out = b\"\".join([bytes([x]) for x in out])\n",
    "    return out.decode('utf-8', errors='replace')\n",
    "decoded = decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e2fc6739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upto = 10000\n",
    "decoded[:upto] == text[:upto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f691f5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(99, 99): 256,\n",
       " (79, 41): 257,\n",
       " (99, 49): 258,\n",
       " (40, 61): 259,\n",
       " (259, 257): 260,\n",
       " (99, 40): 261,\n",
       " (67, 67): 262,\n",
       " (99, 50): 263,\n",
       " (41, 67): 264,\n",
       " (258, 256): 265,\n",
       " (99, 51): 266,\n",
       " (261, 256): 267,\n",
       " (67, 260): 268,\n",
       " (72, 93): 269,\n",
       " (10, 67): 270,\n",
       " (263, 256): 271,\n",
       " (91, 67): 272,\n",
       " (272, 64): 273,\n",
       " (40, 67): 274,\n",
       " (10, 265): 275}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f0ffe58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[67, 273, 64, 93, 49, 40, 268, 67, 61, 67, 40, 79, 49, 41]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode(text):\n",
    "    tokens = list(text.encode(\"utf-8\"))\n",
    "    # go through merges in the order they were generated\n",
    "    for pair in merges:\n",
    "        new_tokens = []\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            if i < len(tokens) - 1 and (tokens[i],tokens[i+1]) == pair:\n",
    "                new_tokens.append(merges[pair])\n",
    "                i += 2\n",
    "                continue\n",
    "            new_tokens.append(tokens[i])\n",
    "            i += 1\n",
    "        tokens = new_tokens\n",
    "    return tokens\n",
    "\n",
    "encode(text[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9d676483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = text[:200]\n",
    "sample == decode(encode(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165e68eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
